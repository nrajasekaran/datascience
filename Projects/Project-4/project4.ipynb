{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add scraper to this ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "\n",
    "NLP\n",
    "Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "Ensemble methods and decision tree models\n",
    "SVM models\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. Communication of your process is key. Note that most listings DO NOT come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings.\n",
    "\n",
    "QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "\n",
    "What components of a job posting distinguish data scientists from other data jobs?\n",
    "What features are important for distinguishing junior vs. senior positions?\n",
    "Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance.\n",
    "\n",
    "BONUS PROBLEM\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs. Plot the ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cPickle as pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_cities = ['New+York', 'Chicago', 'San+Francisco', 'San+Jose', 'San+Diego', 'Los+Angeles', 'Washington%2C+DC', 'Boston', 'Pittsburgh', 'Philadelphia', 'Atlanta', 'Cincinnati', 'St.+Louis', 'Tampa', 'Oakland', 'Austin', 'Houston', 'Dallas', 'Seattle', 'Portland', 'Denver', 'Phoenix', 'Minneapolis', 'Miami', 'Charlotte', 'Jacksonville', 'Indianapolis', 'Nashville', 'Kansas+City', 'Columbus']\n",
    "len(indeed_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", 'San+Jose', 'San+Diego', 'Los+Angeles', 'Washington%2C+DC',\n",
    "          'Boston', 'Pittsburgh', 'Philadelphia', 'Atlanta', 'Cincinnati', 'St.+Louis', 'Tampa', 'Oakland',\n",
    "          'Austin', 'Houston', 'Dallas', 'Seattle', 'Portland', 'Denver', 'Phoenix', 'Minneapolis', 'Miami',\n",
    "          'Charlotte', 'Jacksonville', 'Indianapolis', 'Nashville', 'Kansas+City', 'Columbus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape 1 location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "salary = []\n",
    "summary = []\n",
    "skills = []\n",
    "#copy from scraper ipynb 1 loc, no of search result.\n",
    "\n",
    "def scrape(city, results):\n",
    "    \n",
    "    def get_title(soup): \n",
    "        jobs = []\n",
    "        for div in soup.find_all('div', attrs={'class':'row'}):\n",
    "            for a in div.find_all('a', attrs={'data-tn-element':'jobTitle'}):\n",
    "                jobs.append(a['title'])\n",
    "        return jobs\n",
    "\n",
    "    def get_company(soup): \n",
    "        companies = []\n",
    "        for div in soup.find_all('div', attrs={'class':'row'}):\n",
    "            company = div.find_all('span', attrs={'class':'company'})\n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    companies.append(b.text.strip())\n",
    "            else:\n",
    "                sec_try = div.find_all('span', attrs={'class':'result-link-source'})\n",
    "                for span in sec_try:\n",
    "                    companies.append(span.text.strip())\n",
    "\n",
    "        return companies\n",
    "\n",
    "    def get_location(soup): \n",
    "        locations = []\n",
    "        spans = soup.find_all('span', attrs={'class': 'location'})\n",
    "        for span in spans:\n",
    "            locations.append(span.text)\n",
    "        return locations\n",
    "\n",
    "    def get_salary(soup): \n",
    "        salaries = []\n",
    "        for div in soup.find_all('div', attrs={'class':'row'}):\n",
    "            try:\n",
    "                salaries.append(div.find('nobr').text)\n",
    "            except:\n",
    "                try:\n",
    "                    div_two = div.find(name='div',attrs={'class':'sjcl'})\n",
    "                    div_three = div_two.find('div')\n",
    "                    salaries.append(div_three.text.strip())\n",
    "                except:\n",
    "                    salaries.append('NA')\n",
    "        return salaries    \n",
    "    \n",
    "    def get_summary(soup): \n",
    "        summaries = []\n",
    "        spans = soup.find_all('span', attrs={'class': 'summary'})\n",
    "        for span in spans:\n",
    "            summaries.append(span.text.strip())\n",
    "        return summaries\n",
    "    \n",
    "    def get_skill(soup): \n",
    "        skills = []\n",
    "        for div in soup.find_all('div', attrs={'class':'row'}):\n",
    "            try:\n",
    "                skills.append(div.find('span', attrs={'class': 'experienceList'}).text)\n",
    "            except:\n",
    "                skills.append('NA')\n",
    "        return skills  \n",
    "    \n",
    "    \n",
    "  #for city in indeed_cities:\n",
    "   # for start in range(0, max_results_per_city, 100):\n",
    "    #    url = \"https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=\\\n",
    "     #          &salary=&radius=25&l=\" + city + \"&fromage=any&limit=100&start=\" + str(start) + \"&sort=&psf=advsrch\"\n",
    "      #  html = requests.get(url)\n",
    "       # soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        #for result in soup.find_all('div', {'class':' row result'}):\n",
    "         #   results.append(result)\n",
    "       # sleep(1)\n",
    "        \n",
    "    for start in range (0, results, 50):\n",
    "        url = 'https://www.indeed.com/jobs?q=' + 'data+scientist' + '&l=' + city \\\n",
    "            + '&limit=50&radius=25' + '&start=' + str(start)\n",
    "        request = requests.get(url)\n",
    "        soup = BeautifulSoup(request.text, 'html.parser')\n",
    "    \n",
    "        title.extend(get_title(soup))\n",
    "        company.extend(get_company(soup))\n",
    "        location.extend(get_location(soup))\n",
    "        salary.extend(get_salary(soup))\n",
    "        summary.extend(get_summary(soup))\n",
    "        skills.extend(get_skill(soup))\n",
    "        time.sleep(3)\n",
    "        print start, 'scraped.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 scraped.\n",
      "50 scraped.\n",
      "100 scraped.\n",
      "150 scraped.\n",
      "200 scraped.\n",
      "250 scraped.\n",
      "300 scraped.\n",
      "350 scraped.\n",
      "400 scraped.\n",
      "450 scraped.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-d7ae1182f38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindeed_cities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-512a994a7468>\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(city, results)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.indeed.com/jobs?q='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data+scientist'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'&l='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcity\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m'&limit=50&radius=25'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'&start='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    516\u001b[0m         }\n\u001b[1;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                 )\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/connection.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.pyc\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_cert_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcertfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     warnings.warn(\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/requests/packages/urllib3/contrib/pyopenssl.pyc\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0mcnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/OpenSSL/SSL.pyc\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \"\"\"\n\u001b[0;32m-> 1637\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_results = 1000\n",
    "\n",
    "for city in indeed_cities:\n",
    "    scrape(city,max_results)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)\n",
    "\n",
    "#title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['title','company','location','salary','summary','skill'])\n",
    "df.title = title\n",
    "df.company = company\n",
    "df.location = location\n",
    "df.salary = salary\n",
    "df.summary = summary\n",
    "df.skill = skills\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "company     0\n",
       "location    0\n",
       "salary      0\n",
       "summary     0\n",
       "skill       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./indeed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate, Data Scientist</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York, NY 10032 (Washington Heights area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>Utilize experience in applying Machine Learnin...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Quantitative Analyst, Engineering</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>4 years of relevant work experience (e.g., as ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Integrating with external data sources and API...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>New York, NY 10020 (Midtown area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>As well as deployment of advanced techniques (...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>This position will use predictive and behavior...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist, Analytics</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>The Data Scientist Analytics role has work acr...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Worldwide Advanced Analytics ...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>As a member of our team you will get to work h...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist - All Levels (Applied Data ...</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Contribute to research projects involving one ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quantitative Analyst Intern, Summer 2018</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>Specifically, we support the development of in...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Technology - GSAM Tech - Data Science and Mach...</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>New York, NY 10282 (Tribeca area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>IMD Knowledge Management team is looking to ex...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jr. Research Analyst</td>\n",
       "      <td>ValuePenguin</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Follow relevant news, trends and competitors’ ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist - Global Intelligence (New York)</td>\n",
       "      <td>Uber</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>What you'll doWork closely with key stakeholde...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>We are searching for a forward thinking Data S...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Research Scientist, Google Brain (United States)</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>From creating experiments and prototyping impl...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MetroPlus Health Plan</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>\\n$90,000 - $115,000 a year</td>\n",
       "      <td>MetroPlus Health Plan provides the highest qua...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MealPal</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Verify data integrity used in analyses and wor...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Vettery</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build machine learning infrastructure and mode...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>OnDeck</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>As a Data Scientist at OnDeck, you will:. Stro...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Be part of a team of Data Scientists that focu...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>We are looking for talented and experienced Ma...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Cortex is a team of software engineers, data s...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Creative Campaign Effectiveness Research Analyst</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>BA/BS degree in an analytical subject area or ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>OrderGroove, Inc.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>OrderGroove is looking to bring aboard a Data ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jefferies &amp; Company, Inc.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>We are looking for a hands-on-data scientist w...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Rockstar New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Extensive knowledge of machine learning techni...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Impact Radius</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>As a Data Scientist, you will be evaluating ex...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Loadsmart</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>We are looking for a Data Scientist to join us...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Foursquare</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Strategic analytics, marketing analytics, digi...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Butterfly Network</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>You’ll help design analysis plans for clinical...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pamten</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Experience implementing Regression, Bayesian, ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>The McManness Group</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>\\n$89,000 - $113,000 a year</td>\n",
       "      <td>Understanding of health insurance business, cl...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>Big Data Developer (W2 ONY - R, JavaScript, an...</td>\n",
       "      <td>Preferred Resources, Inc.</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build services, deploy models, algorithms, per...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>Medical Research Analyst</td>\n",
       "      <td>Intertel, Inc.</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>\\n$12 an hour</td>\n",
       "      <td>THIS IS NOT A SALES POSITION! NO EXPERIENCE NE...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>Scientist, Process Validation</td>\n",
       "      <td>Patheon</td>\n",
       "      <td>St. Louis, MO 63134</td>\n",
       "      <td>NA</td>\n",
       "      <td>Responsible for following the requirements of ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>Data Scientist - TS/SCI REQUIRED</td>\n",
       "      <td>Bailey Information Technology Consultants, LLC</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Data Scientist TS/SCI Job Description:. Superi...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>Sr. Scientist, MTS</td>\n",
       "      <td>Patheon</td>\n",
       "      <td>St. Louis, MO 63134</td>\n",
       "      <td>NA</td>\n",
       "      <td>This individual may on occassion also lead the...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>Geospatial Analyst (Journeyman)</td>\n",
       "      <td>MESMO Inc.</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Analyze and depict GEOINT collection related i...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>Senior Social Scientist</td>\n",
       "      <td>Helios Global Inc.</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Assisting in data collection and continuous im...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>Project Manager - Data Production</td>\n",
       "      <td>Label Insight</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Work with the Data, Engineering, and Product t...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>Analytics Developer (Big Data Cloud) - Interme...</td>\n",
       "      <td>KellyMitchell</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Work collaboratively with interdisciplinary sc...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>A-Line Staffing Solutions</td>\n",
       "      <td>Richmond Heights, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Develop and champion adoption of population he...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>Operations and Quality Manager</td>\n",
       "      <td>Label Insight</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build and manage vendor relationships - create...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>Analytics Developer (Big Data Cloud) - Entry</td>\n",
       "      <td>KellyMitchell</td>\n",
       "      <td>Chesterfield, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build services, deploy models, algorithms, per...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>Research Scientist 1: Molecular Biology</td>\n",
       "      <td>MRA Member Career Opportunities</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>The ideal candidate will work in close collabo...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>Applications Analyst (Healthcare)</td>\n",
       "      <td>HELP-Hire Healthcare</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>\\n$52 an hour</td>\n",
       "      <td>2 - 5 years of hands on experience with writin...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>Jr. Engineer - Cloud (R/Python)</td>\n",
       "      <td>SBS Creatix LLC</td>\n",
       "      <td>St. Louis, MO 63141</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build services, deploy models, algorithms, per...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>Lead Cloud Engineer - AWS/Big Data</td>\n",
       "      <td>SBS Creatix LLC</td>\n",
       "      <td>Creve Coeur, MO 63141</td>\n",
       "      <td>NA</td>\n",
       "      <td>Build services, deploy models, algorithms, per...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>Software Engineer 2 :: 372919</td>\n",
       "      <td>CTS International</td>\n",
       "      <td>Berkeley, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Skilled scientists and thinkers. Opportunities...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>Senior Analytical Research &amp; Development Scien...</td>\n",
       "      <td>Nesher Pharmaceuticals (USA) LLC</td>\n",
       "      <td>Bridgeton, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Provide expert review of CMC documents, OOS or...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>Jr. Food and Beverage Specialist</td>\n",
       "      <td>Label Insight</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>The Data Transformation team is a highly drive...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>Analytics Developer (Big Data Cloud) - Interme...</td>\n",
       "      <td>Strategic Staffing Solutions</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Will work with Data Engineers, scientist and v...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>Office &amp; People Operations Coordinator</td>\n",
       "      <td>Label Insight</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Our team is unique because it’s comprised not ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>Senior Staff Consultant (SDDC)</td>\n",
       "      <td>IronArch Technology</td>\n",
       "      <td>Scott AFB, IL</td>\n",
       "      <td>NA</td>\n",
       "      <td>IronArch Technology is looking for a talented ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>Design and Analysis Engineer 2 :: 372918</td>\n",
       "      <td>CTS International</td>\n",
       "      <td>Berkeley, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Skilled scientists and thinkers. Data Link exp...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>Jr. Personal Care Specialist</td>\n",
       "      <td>Label Insight</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>The Data Transformation team is a highly drive...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>Applied Statistician - Expert</td>\n",
       "      <td>Strategic Staffing Solutions</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Support the statistical needs of API scientist...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>Electronic Systems Design &amp; Analysis Engineer ...</td>\n",
       "      <td>CTS International</td>\n",
       "      <td>Berkeley, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Skilled scientists and thinkers. Data Link exp...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>Project Coordinator</td>\n",
       "      <td>BEPC Inc</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>NA</td>\n",
       "      <td>Through our program, we’re inspiring curiosity...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>Principal Scientist, Cell Culture Development</td>\n",
       "      <td>Patheon</td>\n",
       "      <td>St. Louis, MO 63134</td>\n",
       "      <td>NA</td>\n",
       "      <td>Design experimental plans based on the defined...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>Science Education Program Coordinator</td>\n",
       "      <td>MilliporeSigma</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>\\n$25 an hour</td>\n",
       "      <td>Through our Curiosity LabsTM program, we’re in...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6132 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                             Associate, Data Scientist   \n",
       "1      Data Scientist/Quantitative Analyst, Engineering   \n",
       "2                                        Data Scientist   \n",
       "3                                        Data Scientist   \n",
       "4                                  Data Science Analyst   \n",
       "5                             Data Scientist, Analytics   \n",
       "6     Data Scientist - Worldwide Advanced Analytics ...   \n",
       "7     Research Scientist - All Levels (Applied Data ...   \n",
       "8              Quantitative Analyst Intern, Summer 2018   \n",
       "9     Technology - GSAM Tech - Data Science and Mach...   \n",
       "10                                 Jr. Research Analyst   \n",
       "11      Data Scientist - Global Intelligence (New York)   \n",
       "12                                       Data Scientist   \n",
       "13     Research Scientist, Google Brain (United States)   \n",
       "14                                       Data Scientist   \n",
       "15                                       Data Scientist   \n",
       "16                                       Data Scientist   \n",
       "17                                       Data Scientist   \n",
       "18                                       Data Scientist   \n",
       "19                                       Data Scientist   \n",
       "20                                     Machine Learning   \n",
       "21     Creative Campaign Effectiveness Research Analyst   \n",
       "22                                       Data Scientist   \n",
       "23                                       Data Scientist   \n",
       "24                                       Data Scientist   \n",
       "25                                       Data Scientist   \n",
       "26                                       Data Scientist   \n",
       "27                                       Data Scientist   \n",
       "28                                       Data Scientist   \n",
       "29                                       Data Scientist   \n",
       "...                                                 ...   \n",
       "6102                              Data Analysis Manager   \n",
       "6103  Big Data Developer (W2 ONY - R, JavaScript, an...   \n",
       "6104                           Medical Research Analyst   \n",
       "6105                      Scientist, Process Validation   \n",
       "6106                   Data Scientist - TS/SCI REQUIRED   \n",
       "6107                                 Sr. Scientist, MTS   \n",
       "6108                    Geospatial Analyst (Journeyman)   \n",
       "6109                            Senior Social Scientist   \n",
       "6110                  Project Manager - Data Production   \n",
       "6111  Analytics Developer (Big Data Cloud) - Interme...   \n",
       "6112                              Data Analysis Manager   \n",
       "6113                     Operations and Quality Manager   \n",
       "6114       Analytics Developer (Big Data Cloud) - Entry   \n",
       "6115            Research Scientist 1: Molecular Biology   \n",
       "6116                  Applications Analyst (Healthcare)   \n",
       "6117                    Jr. Engineer - Cloud (R/Python)   \n",
       "6118                 Lead Cloud Engineer - AWS/Big Data   \n",
       "6119                      Software Engineer 2 :: 372919   \n",
       "6120  Senior Analytical Research & Development Scien...   \n",
       "6121                   Jr. Food and Beverage Specialist   \n",
       "6122  Analytics Developer (Big Data Cloud) - Interme...   \n",
       "6123             Office & People Operations Coordinator   \n",
       "6124                     Senior Staff Consultant (SDDC)   \n",
       "6125           Design and Analysis Engineer 2 :: 372918   \n",
       "6126                       Jr. Personal Care Specialist   \n",
       "6127                      Applied Statistician - Expert   \n",
       "6128  Electronic Systems Design & Analysis Engineer ...   \n",
       "6129                                Project Coordinator   \n",
       "6130      Principal Scientist, Cell Culture Development   \n",
       "6131              Science Education Program Coordinator   \n",
       "\n",
       "                                             company  \\\n",
       "0                                     Morgan Stanley   \n",
       "1                                             Google   \n",
       "2                                        Capital One   \n",
       "3                                    Bank of America   \n",
       "4                                              Aetna   \n",
       "5                                           Facebook   \n",
       "6                                                IBM   \n",
       "7                                Columbia University   \n",
       "8                                             Google   \n",
       "9                                      Goldman Sachs   \n",
       "10                                      ValuePenguin   \n",
       "11                                              Uber   \n",
       "12                                       Foot Locker   \n",
       "13                                            Google   \n",
       "14                             MetroPlus Health Plan   \n",
       "15                                           MealPal   \n",
       "16                                           Vettery   \n",
       "17                                            OnDeck   \n",
       "18                                      NBCUniversal   \n",
       "19                         Amazon Web Services, Inc.   \n",
       "20                                           Twitter   \n",
       "21                                            Google   \n",
       "22                                 OrderGroove, Inc.   \n",
       "23                         Jefferies & Company, Inc.   \n",
       "24                                 Rockstar New York   \n",
       "25                                     Impact Radius   \n",
       "26                                         Loadsmart   \n",
       "27                                        Foursquare   \n",
       "28                                 Butterfly Network   \n",
       "29                                            Pamten   \n",
       "...                                              ...   \n",
       "6102                             The McManness Group   \n",
       "6103                       Preferred Resources, Inc.   \n",
       "6104                                  Intertel, Inc.   \n",
       "6105                                         Patheon   \n",
       "6106  Bailey Information Technology Consultants, LLC   \n",
       "6107                                         Patheon   \n",
       "6108                                      MESMO Inc.   \n",
       "6109                              Helios Global Inc.   \n",
       "6110                                   Label Insight   \n",
       "6111                                   KellyMitchell   \n",
       "6112                       A-Line Staffing Solutions   \n",
       "6113                                   Label Insight   \n",
       "6114                                   KellyMitchell   \n",
       "6115                 MRA Member Career Opportunities   \n",
       "6116                            HELP-Hire Healthcare   \n",
       "6117                                 SBS Creatix LLC   \n",
       "6118                                 SBS Creatix LLC   \n",
       "6119                               CTS International   \n",
       "6120                Nesher Pharmaceuticals (USA) LLC   \n",
       "6121                                   Label Insight   \n",
       "6122                    Strategic Staffing Solutions   \n",
       "6123                                   Label Insight   \n",
       "6124                             IronArch Technology   \n",
       "6125                               CTS International   \n",
       "6126                                   Label Insight   \n",
       "6127                    Strategic Staffing Solutions   \n",
       "6128                               CTS International   \n",
       "6129                                        BEPC Inc   \n",
       "6130                                         Patheon   \n",
       "6131                                  MilliporeSigma   \n",
       "\n",
       "                                          location  \\\n",
       "0     New York, NY 10032 (Washington Heights area)   \n",
       "1                New York, NY 10011 (Chelsea area)   \n",
       "2                                     New York, NY   \n",
       "3                New York, NY 10020 (Midtown area)   \n",
       "4               New York, NY 10016 (Gramercy area)   \n",
       "5                                     New York, NY   \n",
       "6                                     New York, NY   \n",
       "7                                     New York, NY   \n",
       "8                New York, NY 10011 (Chelsea area)   \n",
       "9                New York, NY 10282 (Tribeca area)   \n",
       "10                                    New York, NY   \n",
       "11               New York, NY 10001 (Chelsea area)   \n",
       "12                                    New York, NY   \n",
       "13               New York, NY 10011 (Chelsea area)   \n",
       "14                                    New York, NY   \n",
       "15                                    New York, NY   \n",
       "16                                    New York, NY   \n",
       "17                                    New York, NY   \n",
       "18                                    New York, NY   \n",
       "19                                    New York, NY   \n",
       "20                                    New York, NY   \n",
       "21               New York, NY 10011 (Chelsea area)   \n",
       "22                                    New York, NY   \n",
       "23                                    New York, NY   \n",
       "24                                    New York, NY   \n",
       "25                                    New York, NY   \n",
       "26                                    New York, NY   \n",
       "27                                    New York, NY   \n",
       "28                                    New York, NY   \n",
       "29                                    New York, NY   \n",
       "...                                            ...   \n",
       "6102                                 St. Louis, MO   \n",
       "6103                                 St. Louis, MO   \n",
       "6104                                 St. Louis, MO   \n",
       "6105                           St. Louis, MO 63134   \n",
       "6106                                 St. Louis, MO   \n",
       "6107                           St. Louis, MO 63134   \n",
       "6108                                 St. Louis, MO   \n",
       "6109                                 St. Louis, MO   \n",
       "6110                                 St. Louis, MO   \n",
       "6111                                 St. Louis, MO   \n",
       "6112                          Richmond Heights, MO   \n",
       "6113                                 St. Louis, MO   \n",
       "6114                              Chesterfield, MO   \n",
       "6115                                 St. Louis, MO   \n",
       "6116                                 St. Louis, MO   \n",
       "6117                           St. Louis, MO 63141   \n",
       "6118                         Creve Coeur, MO 63141   \n",
       "6119                                  Berkeley, MO   \n",
       "6120                                 Bridgeton, MO   \n",
       "6121                                 St. Louis, MO   \n",
       "6122                                 St. Louis, MO   \n",
       "6123                                 St. Louis, MO   \n",
       "6124                                 Scott AFB, IL   \n",
       "6125                                  Berkeley, MO   \n",
       "6126                                 St. Louis, MO   \n",
       "6127                                 St. Louis, MO   \n",
       "6128                                  Berkeley, MO   \n",
       "6129                                 St. Louis, MO   \n",
       "6130                           St. Louis, MO 63134   \n",
       "6131                                 St. Louis, MO   \n",
       "\n",
       "                           salary  \\\n",
       "0                              NA   \n",
       "1                              NA   \n",
       "2                              NA   \n",
       "3                              NA   \n",
       "4                              NA   \n",
       "5                              NA   \n",
       "6                              NA   \n",
       "7                              NA   \n",
       "8                              NA   \n",
       "9                              NA   \n",
       "10                             NA   \n",
       "11                             NA   \n",
       "12                             NA   \n",
       "13                             NA   \n",
       "14    \\n$90,000 - $115,000 a year   \n",
       "15                             NA   \n",
       "16                             NA   \n",
       "17                             NA   \n",
       "18                             NA   \n",
       "19                             NA   \n",
       "20                             NA   \n",
       "21                             NA   \n",
       "22                             NA   \n",
       "23                             NA   \n",
       "24                             NA   \n",
       "25                             NA   \n",
       "26                             NA   \n",
       "27                             NA   \n",
       "28                             NA   \n",
       "29                             NA   \n",
       "...                           ...   \n",
       "6102  \\n$89,000 - $113,000 a year   \n",
       "6103                           NA   \n",
       "6104                \\n$12 an hour   \n",
       "6105                           NA   \n",
       "6106                           NA   \n",
       "6107                           NA   \n",
       "6108                           NA   \n",
       "6109                           NA   \n",
       "6110                           NA   \n",
       "6111                           NA   \n",
       "6112                           NA   \n",
       "6113                           NA   \n",
       "6114                           NA   \n",
       "6115                           NA   \n",
       "6116                \\n$52 an hour   \n",
       "6117                           NA   \n",
       "6118                           NA   \n",
       "6119                           NA   \n",
       "6120                           NA   \n",
       "6121                           NA   \n",
       "6122                           NA   \n",
       "6123                           NA   \n",
       "6124                           NA   \n",
       "6125                           NA   \n",
       "6126                           NA   \n",
       "6127                           NA   \n",
       "6128                           NA   \n",
       "6129                           NA   \n",
       "6130                           NA   \n",
       "6131                \\n$25 an hour   \n",
       "\n",
       "                                                summary skill  \n",
       "0     Utilize experience in applying Machine Learnin...    NA  \n",
       "1     4 years of relevant work experience (e.g., as ...    NA  \n",
       "2     Integrating with external data sources and API...    NA  \n",
       "3     As well as deployment of advanced techniques (...    NA  \n",
       "4     This position will use predictive and behavior...    NA  \n",
       "5     The Data Scientist Analytics role has work acr...    NA  \n",
       "6     As a member of our team you will get to work h...    NA  \n",
       "7     Contribute to research projects involving one ...    NA  \n",
       "8     Specifically, we support the development of in...    NA  \n",
       "9     IMD Knowledge Management team is looking to ex...    NA  \n",
       "10    Follow relevant news, trends and competitors’ ...    NA  \n",
       "11    What you'll doWork closely with key stakeholde...    NA  \n",
       "12    We are searching for a forward thinking Data S...    NA  \n",
       "13    From creating experiments and prototyping impl...    NA  \n",
       "14    MetroPlus Health Plan provides the highest qua...    NA  \n",
       "15    Verify data integrity used in analyses and wor...    NA  \n",
       "16    Build machine learning infrastructure and mode...    NA  \n",
       "17    As a Data Scientist at OnDeck, you will:. Stro...    NA  \n",
       "18    Be part of a team of Data Scientists that focu...    NA  \n",
       "19    We are looking for talented and experienced Ma...    NA  \n",
       "20    Cortex is a team of software engineers, data s...    NA  \n",
       "21    BA/BS degree in an analytical subject area or ...    NA  \n",
       "22    OrderGroove is looking to bring aboard a Data ...    NA  \n",
       "23    We are looking for a hands-on-data scientist w...    NA  \n",
       "24    Extensive knowledge of machine learning techni...    NA  \n",
       "25    As a Data Scientist, you will be evaluating ex...    NA  \n",
       "26    We are looking for a Data Scientist to join us...    NA  \n",
       "27    Strategic analytics, marketing analytics, digi...    NA  \n",
       "28    You’ll help design analysis plans for clinical...    NA  \n",
       "29    Experience implementing Regression, Bayesian, ...    NA  \n",
       "...                                                 ...   ...  \n",
       "6102  Understanding of health insurance business, cl...    NA  \n",
       "6103  Build services, deploy models, algorithms, per...    NA  \n",
       "6104  THIS IS NOT A SALES POSITION! NO EXPERIENCE NE...    NA  \n",
       "6105  Responsible for following the requirements of ...    NA  \n",
       "6106  Data Scientist TS/SCI Job Description:. Superi...    NA  \n",
       "6107  This individual may on occassion also lead the...    NA  \n",
       "6108  Analyze and depict GEOINT collection related i...    NA  \n",
       "6109  Assisting in data collection and continuous im...    NA  \n",
       "6110  Work with the Data, Engineering, and Product t...    NA  \n",
       "6111  Work collaboratively with interdisciplinary sc...    NA  \n",
       "6112  Develop and champion adoption of population he...    NA  \n",
       "6113  Build and manage vendor relationships - create...    NA  \n",
       "6114  Build services, deploy models, algorithms, per...    NA  \n",
       "6115  The ideal candidate will work in close collabo...    NA  \n",
       "6116  2 - 5 years of hands on experience with writin...    NA  \n",
       "6117  Build services, deploy models, algorithms, per...    NA  \n",
       "6118  Build services, deploy models, algorithms, per...    NA  \n",
       "6119  Skilled scientists and thinkers. Opportunities...    NA  \n",
       "6120  Provide expert review of CMC documents, OOS or...    NA  \n",
       "6121  The Data Transformation team is a highly drive...    NA  \n",
       "6122  Will work with Data Engineers, scientist and v...    NA  \n",
       "6123  Our team is unique because it’s comprised not ...    NA  \n",
       "6124  IronArch Technology is looking for a talented ...    NA  \n",
       "6125  Skilled scientists and thinkers. Data Link exp...    NA  \n",
       "6126  The Data Transformation team is a highly drive...    NA  \n",
       "6127  Support the statistical needs of API scientist...    NA  \n",
       "6128  Skilled scientists and thinkers. Data Link exp...    NA  \n",
       "6129  Through our program, we’re inspiring curiosity...    NA  \n",
       "6130  Design experimental plans based on the defined...    NA  \n",
       "6131  Through our Curiosity LabsTM program, we’re in...    NA  \n",
       "\n",
       "[6132 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_pickle(\"./indeed.pkl\")\n",
    "\n",
    "file1 = open(\"./indeed.pkl\",'r')\n",
    "openfile = pickle.load(file1)\n",
    "openfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5012, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our rows after removing duplicates\n",
    "\n",
    "df1 = new_df[~new_df.duplicated()]\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate, Data Scientist</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York, NY 10032 (Washington Heights area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>Utilize experience in applying Machine Learnin...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Quantitative Analyst, Engineering</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>4 years of relevant work experience (e.g., as ...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NA</td>\n",
       "      <td>Integrating with external data sources and API...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>New York, NY 10020 (Midtown area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>As well as deployment of advanced techniques (...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>NA</td>\n",
       "      <td>This position will use predictive and behavior...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title          company  \\\n",
       "0                         Associate, Data Scientist   Morgan Stanley   \n",
       "1  Data Scientist/Quantitative Analyst, Engineering           Google   \n",
       "2                                    Data Scientist      Capital One   \n",
       "3                                    Data Scientist  Bank of America   \n",
       "4                              Data Science Analyst            Aetna   \n",
       "\n",
       "                                       location salary  \\\n",
       "0  New York, NY 10032 (Washington Heights area)     NA   \n",
       "1             New York, NY 10011 (Chelsea area)     NA   \n",
       "2                                  New York, NY     NA   \n",
       "3             New York, NY 10020 (Midtown area)     NA   \n",
       "4            New York, NY 10016 (Gramercy area)     NA   \n",
       "\n",
       "                                             summary skill  \n",
       "0  Utilize experience in applying Machine Learnin...    NA  \n",
       "1  4 years of relevant work experience (e.g., as ...    NA  \n",
       "2  Integrating with external data sources and API...    NA  \n",
       "3  As well as deployment of advanced techniques (...    NA  \n",
       "4  This position will use predictive and behavior...    NA  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title       object\n",
      "company     object\n",
      "location    object\n",
      "salary      object\n",
      "summary     object\n",
      "skill       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print df1.dtypes\n",
    "\n",
    "df1.location = df1.location.astype(str)\n",
    "\n",
    "print df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def to_state(loc):\n",
    "    if 'CA' in loc:\n",
    "        loc = 'California'\n",
    "    elif 'AZ' in loc:\n",
    "        loc = 'Arizona'\n",
    "    elif 'CO' in loc:\n",
    "        loc = 'Colorado'\n",
    "    elif 'CT' in loc:\n",
    "        loc = 'Connecticut'\n",
    "    elif 'MA' in loc:\n",
    "        loc = 'Massachusetts'\n",
    "    elif 'NY' in loc:\n",
    "        loc = 'New York'\n",
    "    elif 'NC' in loc:\n",
    "        loc = 'North Carolina'\n",
    "    elif 'TX' in loc:\n",
    "        loc = 'Texas'\n",
    "    elif 'PA' in loc:\n",
    "        loc = 'Pennsylvania'\n",
    "    elif 'VA' in loc:\n",
    "        loc = 'Virginia'\n",
    "    elif 'WA' in loc:\n",
    "        loc = 'Washington'\n",
    "    elif 'FL' in loc:\n",
    "        loc = 'Florida'\n",
    "    elif 'IL' in loc:\n",
    "        loc = 'Illinois'\n",
    "    elif 'IN' in loc:\n",
    "        loc = 'Indiana'\n",
    "    elif 'IA' in loc:\n",
    "        loc = 'Iowa'\n",
    "    elif 'MD' in loc:\n",
    "        loc = 'Maryland'\n",
    "    elif 'New York' in loc:\n",
    "        loc = 'New York'\n",
    "    else:\n",
    "        loc = loc\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply function to change values to state names\n",
    "df1.location = df1.location.map(to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California                                                1777\n",
       "Pennsylvania                                               606\n",
       "Illinois                                                   482\n",
       "New York                                                   461\n",
       "Massachusetts                                              414\n",
       "St. Louis, MO                                              201\n",
       "Virginia                                                   199\n",
       "Atlanta, GA                                                194\n",
       "Washington, DC                                             113\n",
       "Maryland                                                    86\n",
       "Cincinnati, OH                                              77\n",
       "Alpharetta, GA                                              42\n",
       "Wilmington, DE                                              24\n",
       "Atlanta, GA 30318 (Rockdale area)                           19\n",
       "Atlanta, GA 30338                                           14\n",
       "Wilmington, DE 19801                                        12\n",
       "Atlanta, GA 30308 (Old Fourth Ward area)                    11\n",
       "Norcross, GA                                                11\n",
       "Washington, DC 20005 (Logan Circle area)                    10\n",
       "Washington, DC 20036 (Downtown area)                        10\n",
       "Kennesaw, GA 30144                                           9\n",
       "St. Louis, MO 63141                                          8\n",
       "Cincinnati, OH 45212 (Pleasant Ridge area)                   8\n",
       "Chesterfield, MO                                             8\n",
       "Covington, KY 41011                                          8\n",
       "Kennesaw, GA                                                 8\n",
       "Atlanta, GA 30339                                            7\n",
       "Berkeley, MO                                                 6\n",
       "St. Louis, MO 63134                                          6\n",
       "Smyrna, GA                                                   5\n",
       "                                                          ... \n",
       "Wilmington, DE 19809                                         1\n",
       "Moorestown, NJ 08057                                         1\n",
       "Atlanta, GA 30363 (Buckhead area)                            1\n",
       "Bolling AFB, DC                                              1\n",
       "St. Louis, MO 63126                                          1\n",
       "Washington, DC 20022 (Brentwood area)                        1\n",
       "Mount Laurel, NJ                                             1\n",
       "Wilmington, DE 19894                                         1\n",
       "Atlanta, GA 30341                                            1\n",
       "Atlanta, GA 30320                                            1\n",
       "Cherry Hill, NJ                                              1\n",
       "Wilmington, DE 19803                                         1\n",
       "Cherry Hill, NJ 08003                                        1\n",
       "St. Louis, MO 63102 (Near North Riverfront area)             1\n",
       "Cambridge, NJ                                                1\n",
       "Washington, DC 20006 (Foggy Bottom area)                     1\n",
       "Atlanta, GA 30354 (Lakewood Heights-Southeastern area)       1\n",
       "Washington, DC 20032 (Anacostia area)                        1\n",
       "Peachtree Corners, GA                                        1\n",
       "St. Louis, MO 63118 (Benton Park area)                       1\n",
       "Atlanta, GA 30329                                            1\n",
       "Camden, NJ 08103                                             1\n",
       "St. Louis, MO 63105                                          1\n",
       "Atlanta, GA 30333                                            1\n",
       "Atlanta, GA 30327 (Buckhead area)                            1\n",
       "Decatur, GA                                                  1\n",
       "St. Louis, MO 63122                                          1\n",
       "Dunwoody, GA 30338                                           1\n",
       "Cincinnati, OH 45249                                         1\n",
       "Washington, DC 20004 (Downtown area)                         1\n",
       "Name: location, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values of location column to make sure there are only state names, and no stray values\n",
    "df1.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove and replace certain symbols for easier processing thereafter (splitting by '-' to obtain each element)\n",
    "df1.salary = df1.salary.map(lambda x: x.replace('\\n','').replace('$','').replace(',', '').replace(' a ', '-').replace(' - ','-').replace(' an ', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Naren/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1['low'] = df1.salary.map(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['time'] = df1.salary.map(lambda x: x.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-fe62184fe49c>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-82-fe62184fe49c>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create function to get upper bound of salary\n",
    "\n",
    "def upper(sal):\n",
    "   try:\n",
    "        x = sal.split('-')[1]  \n",
    "        for i in x:  \n",
    "            if i in 'abcdefghijklmnopqrstuvwxyz':  \n",
    "                x = np.nan \n",
    "                return x\n",
    "                except:\n",
    "                    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map function to create column for upper bound of salary\n",
    "#df['r2'] = df.salary.map(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>skill</th>\n",
       "      <th>r1</th>\n",
       "      <th>per</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate, Data Scientist</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>Utilize experience in applying Machine Learnin...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Quantitative Analyst, Engineering</td>\n",
       "      <td>Google</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>4 years of relevant work experience (e.g., as ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>Integrating with external data sources and API...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>As well as deployment of advanced techniques (...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>This position will use predictive and behavior...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title          company  \\\n",
       "0                         Associate, Data Scientist   Morgan Stanley   \n",
       "1  Data Scientist/Quantitative Analyst, Engineering           Google   \n",
       "2                                    Data Scientist      Capital One   \n",
       "3                                    Data Scientist  Bank of America   \n",
       "4                              Data Science Analyst            Aetna   \n",
       "\n",
       "   location salary                                            summary skill  \\\n",
       "0  New York     NA  Utilize experience in applying Machine Learnin...    NA   \n",
       "1  New York     NA  4 years of relevant work experience (e.g., as ...    NA   \n",
       "2  New York     NA  Integrating with external data sources and API...    NA   \n",
       "3  New York     NA  As well as deployment of advanced techniques (...    NA   \n",
       "4  New York     NA  This position will use predictive and behavior...    NA   \n",
       "\n",
       "   r1 per   r2  \n",
       "0  NA  NA  NaN  \n",
       "1  NA  NA  NaN  \n",
       "2  NA  NA  NaN  \n",
       "3  NA  NA  NaN  \n",
       "4  NA  NA  NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-aa576a5eddb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df1.time = df1.time.map(lambda x: 12 if x == 'month' else 52 if x == 'week' else\n",
      "\u001b[0;32m/Users/Naren/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;31m# arg is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66440)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-aa576a5eddb3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df1.time = df1.time.map(lambda x: 12 if x == 'month' else 52 if x == 'week' else\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
